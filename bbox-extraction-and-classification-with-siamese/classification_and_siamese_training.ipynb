{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.basic_data import *\n",
    "from skimage.util import montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch import optim\n",
    "import re\n",
    "import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastprogress import force_console_behavior\n",
    "import fastprogress\n",
    "fastprogress.fastprogress.NO_BAR = True\n",
    "master_bar, progress_bar = force_console_behavior()\n",
    "fastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = albumentations.Compose([\n",
    "    albumentations.RandomBrightnessContrast(p=0.75),\n",
    "    albumentations.ShiftScaleRotate(shift_limit=0, scale_limit=0.1, rotate_limit=10, interpolation=2, p=0.75)\n",
    "])\n",
    "\n",
    "composed_augs = albumentations.Compose([\n",
    "    albumentations.RandomBrightnessContrast(p=0.75),\n",
    "    albumentations.ShiftScaleRotate(shift_limit=0, scale_limit=0.1, rotate_limit=10, interpolation=2, p=0.75)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(ary):\n",
    "    return composed_augs(image=ary)['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_to_files_in(dir):\n",
    "    paths = []\n",
    "    for path in Path(dir).iterdir():\n",
    "        if path.is_dir():\n",
    "            paths += paths_to_files_in(path)\n",
    "        else:\n",
    "            paths.append(path)\n",
    "    return paths\n",
    "\n",
    "def open_image(path): return PIL.Image.open(path).convert('RGB')\n",
    "\n",
    "def image2ary(image): return np.asarray(image)\n",
    "\n",
    "def ary2tensor(ary, dtype=np.float32): return torch.from_numpy(ary.astype(dtype, copy=False))\n",
    "\n",
    "def image2tensor(image, augment_fn=None):\n",
    "    ary = image2ary(image)\n",
    "    if augment_fn: ary = augment_fn(ary)\n",
    "    ary = ary.transpose(2, 0, 1)\n",
    "    tensor = ary2tensor(ary)\n",
    "    return tensor.div_(255)\n",
    "\n",
    "imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "mean, std = torch.from_numpy(np.array(imagenet_stats).astype(np.float32))\n",
    "\n",
    "def imagenet_normalize(tensor):\n",
    "    zero_centered = tensor - mean[:, None, None]\n",
    "    return zero_centered / std[:, None, None]\n",
    "\n",
    "def imagenet_denormalize(zero_centered):\n",
    "    zero_centered = zero_centered * std[:, None, None]\n",
    "    return zero_centered + mean[:, None, None]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, items, reader, labeler):\n",
    "        self.items, self.reader, self.labeler = items, reader, labeler\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.items[idx]\n",
    "        return self.reader(item), self.labeler(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reader():\n",
    "    def __init__(self, path, augment_fn=None):\n",
    "        self.path = path\n",
    "        self.augment_fn = augment_fn\n",
    "    def __call__(self, fns):\n",
    "        paths = [f'{self.path}/{filename}' for filename in fns]\n",
    "        images = [open_image(image_path) for image_path in paths]\n",
    "        tensors = [image2tensor(image, augment_fn = self.augment_fn) for image in images]\n",
    "        return [imagenet_normalize(tensor) for tensor in tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5005"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/train.csv').Id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Labeler():\n",
    "    def __init__(self):\n",
    "        df = pd.read_csv('data/train.csv')\n",
    "        self.fn2label = {}\n",
    "        for row in df[df.Id != 'new_whale'].itertuples():\n",
    "            self.fn2label[row.Image] = row.Id\n",
    "        self.classes = sorted(list(set(list(self.fn2label.values()))))\n",
    "    def __call__(self, fns):\n",
    "        labels = [self.fn2label[fn] for fn in fns]\n",
    "        # if 2 imgs have same label, return [label1_idx,label1_idx,0]. Else return [label1_idx,label2_idx,1]\n",
    "        return [self.classes.index(label) for label in labels] + [1 if labels[0] != labels[1] else 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_basic_dataloader(sz, batch_size, num_workers=12):\n",
    "    reader = Reader(f'data/train-extracted-{sz}')\n",
    "    basic_ds = Dataset([*zip(df.Image.tolist(), df.Image.tolist())], reader, labeler)\n",
    "    return DataLoader(basic_ds, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 224\n",
    "NUM_WORKERS = 12\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When I refer to 'whale', I mean a particular image (the file name).\n",
    "\n",
    "df = pd.read_csv('data/train.csv')\n",
    "df = df[df.Id != 'new_whale']\n",
    "images_without_meaningful_bbox_predictions = \\\n",
    "    ['85a95e7a8.jpg', 'b370e1339.jpg', 'b4cb30afd.jpg', 'd4cb9d6e4.jpg', '6a72d84ca.jpg']\n",
    "df = df[~df.Image.isin(images_without_meaningful_bbox_predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>w_f48451c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>w_c3d896a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>w_20df2c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000a6daec.jpg</td>\n",
       "      <td>w_dd88965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0016b897a.jpg</td>\n",
       "      <td>w_64404ac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image         Id\n",
       "0  0000e88ab.jpg  w_f48451c\n",
       "1  0001f9222.jpg  w_c3d896a\n",
       "2  00029d126.jpg  w_20df2c5\n",
       "6  000a6daec.jpg  w_dd88965\n",
       "8  0016b897a.jpg  w_64404ac"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeler = Labeler()\n",
    "\n",
    "df.head() # no new whale and imgs with nonsense bbox prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_dataloader = create_basic_dataloader(SZ, BS, NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(basic_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([32, 3, 224, 224]), torch.Size([32, 3, 224, 224]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x),x[0].shape,x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " tensor([4785, 3807,  661, 4314, 1928]),\n",
       " tensor([4785, 3807,  661, 4314, 1928]),\n",
       " tensor([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y),y[0][:5],y[1][:5],y[2][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[2] # ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):  # Siamese + classification\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(*list(models.resnet50(True).children())[:-2]) #out: (bn,?,? 2048)\n",
    "        self.head = create_head(4096 # adaptive concat pool (2048*2)\n",
    "                                , 5004, [2048]) # out: 5004 (# of classes ignoring new whale)\n",
    "        self.ada_concat = AdaptiveConcatPool2d(1)\n",
    "\n",
    "    def forward(self, ims_a, ims_b):\n",
    "        cnn_out_a = self.cnn(ims_a) # (bs,?,?,2048), will also be returned after concat pool (for siamese). Output shape (bs,2048*2)\n",
    "        out_a = self.head(cnn_out_a) # (bs,5004), will be returned for classification\n",
    "        \n",
    "        cnn_out_b = self.cnn(ims_b) # (bs,?,?,2048)\n",
    "        out_b = self.head(cnn_out_b) # (bs,5004)\n",
    "    \n",
    "        return out_a, out_b, self.ada_concat(cnn_out_a).squeeze(), self.ada_concat(cnn_out_b).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(models.resnet50(True).children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): AdaptiveConcatPool2d(\n",
       "    (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "    (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "  )\n",
       "  (1): Flatten()\n",
       "  (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): Dropout(p=0.25)\n",
       "  (4): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "  (5): ReLU(inplace)\n",
       "  (6): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Dropout(p=0.5)\n",
       "  (8): Linear(in_features=2048, out_features=5004, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1 = create_head(4096, 5004, [2048])\n",
    "temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (0): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck(\n",
       "     (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "   )\n",
       "   (2): Bottleneck(\n",
       "     (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "   )\n",
       " ),\n",
       " AvgPool2d(kernel_size=7, stride=1, padding=0),\n",
       " Linear(in_features=2048, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \n",
    "    loss = mean( (1-Y)*0.5* e_dist**2 + Y*0.5* max(0,m-e_dist)**2 )\n",
    "    \n",
    "    e_dist: euclidean distance b/t 2 outputs \n",
    "    Y     : 0 if same class, else 1\n",
    "    m     : upper limit for dissimilar pairs (>0). Dissimilar pairs beyond this margin will not contribute to the loss\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MARGIN = 60\n",
    "\n",
    "def cross_entropy_loss(preds, labels_a, labels_b, diff_class_ind):\n",
    "    return F.cross_entropy(preds[0], labels_a) + F.cross_entropy(preds[1], labels_b)\n",
    "\n",
    "def contr_loss(preds, labels_a, labels_b, diff_class_ind):\n",
    "    c_loss = ContrastiveLoss(MARGIN)\n",
    "    return c_loss(preds[2], preds[3], diff_class_ind.float())\n",
    "\n",
    "def loss_fn(preds, labels_a, labels_b, diff_class_ind):\n",
    "    # combine C.E and Contrastive\n",
    "    # 10*CE_loss + 1/25 contr_loss\n",
    "    return 10 * cross_entropy_loss(preds, labels_a, labels_b, diff_class_ind) + contr_loss(preds, labels_a, labels_b, diff_class_ind) / 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_mod(preds, labels_a, labels_b, diff_class_ind):\n",
    "    return 0.5 * accuracy(preds[0], labels_a) + 0.5 * accuracy(preds[1], labels_b)\n",
    "\n",
    "def map5_mod(preds, labels_a, labels_b, diff_class_ind):\n",
    "    return 0.5 * map5(preds[0], labels_a) + 0.5 * map5(preds[1], labels_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start loading data using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_similarity_dict(model, dataloader):\n",
    "    # Calculating descriptors for each image\n",
    "    descs = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            ims = batch[0][0].cuda() # get batch of 1st img (bs,3,224,224)\n",
    "            cnn_out = learn.model.cnn(ims) # (bn,?,? 2048)\n",
    "            descs.append(learn.model.ada_concat(cnn_out).squeeze().detach().cpu()) # (bs,2048*2)\n",
    "\n",
    "    descs = torch.cat(descs).cuda() # (# of imgs, 2048*2)\n",
    "\n",
    "    # Calculating similarity dict for each image\n",
    "    dists = {}\n",
    "    # { img0_name: [dist(img0,img0),dist(img0,img1) ... ] \n",
    "    #   img1_name: [dist(img1,img0),dist(img1,img1) ] \n",
    "    #}\n",
    "    for i, (whale, _) in enumerate(dataloader.items): \n",
    "        dists[whale] = torch.pairwise_distance(descs[i], descs).cpu().numpy()    \n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0000e88ab.jpg', '0000e88ab.jpg')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic_dataloader.items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a fake data just to get learn.model? There has to be a better way\n",
    "\n",
    "def create_fake_data(): # needed for loading the model\n",
    "    fake_ds = Dataset([],_,_)\n",
    "    fake_dl = DataLoader(fake_ds)\n",
    "\n",
    "    data = DataBunch(fake_dl, fake_dl)\n",
    "    data.train_ds.loss_func = lambda: None \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(create_fake_data(), CustomModel(), loss_func=loss_fn, metrics=[accuracy_mod, map5_mod, cross_entropy_loss, contr_loss])\n",
    "learn = learn.clip_grad()\n",
    "learn.split((learn.model.cnn[6], learn.model.head));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from untrain model!\n",
    "dists = create_similarity_dict(learn.model, basic_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15694,),\n",
       " array([6.400001e-05, 5.041779e+01, 5.549538e+01, 6.339818e+01, 5.291072e+01], dtype=float32))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists['0000e88ab.jpg'].shape,dists['0000e88ab.jpg'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(sz, dist_dict, batch_size, k=20, num_workers=12, train_on_both_train_and_val=False):\n",
    "    reader_aug = Reader(f'data/train-extracted-{sz}', augment_fn=augment)\n",
    "    reader = Reader(f'data/train-extracted-{sz}')\n",
    "    \n",
    "    val_fns = list(pd.read_pickle('data/val_fname_no_nw.pkl'))\n",
    "    val_fns_set = set(val_fns)\n",
    "\n",
    "    trn_df = df[~df.Image.isin(val_fns)]\n",
    "    val_df = df[df.Image.isin(val_fns)]\n",
    "    \n",
    "    # TODO: this is poorly written\n",
    "    ds_on_which_dists_were_calculated = Dataset([*zip(df.Image.tolist(), df.Image.tolist())], reader, labeler)\n",
    "    \n",
    "    uniq_whales = df.Id.unique().tolist() if train_on_both_train_and_val else trn_df.Id.unique().tolist()\n",
    "\n",
    "    def sample_other_whale():\n",
    "        # sample 1 img from k 'toughest match' from 'this_whale'\n",
    "        candidate_whales = dist_dict[this_whale].argsort() \n",
    "        this_whale_class = labeler.fn2label[this_whale]\n",
    "        candidate_fns = []\n",
    "        for i in range(200):\n",
    "            # 1st img_fn from ds_on_which_dists_were_calculated (with idx, going from lowest dist to 'this_whale' to 200th dist) \n",
    "            candidate_whale = ds_on_which_dists_were_calculated.items[candidate_whales[i]][0] # \n",
    "            \n",
    "            # add to 'candidate whale' fns list if the candidate_fname not in val fns and have different label than 'this_whale'\n",
    "            if (candidate_whale not in val_fns_set) and (labeler.fn2label[candidate_whale] != this_whale_class): \n",
    "                candidate_fns.append(candidate_whale)\n",
    "                \n",
    "            # we only need k values of candidate whale fns\n",
    "            if len(candidate_fns) == k: break \n",
    "        np.random.shuffle(candidate_fns) # randomly pick one from K toughest matches. TODO: toughest? argsort return closest dist first\n",
    "        return candidate_fns[0]\n",
    "\n",
    "    def sample_this_whale(): \n",
    "        # sample one img from given IDs\n",
    "        return this_whale_df.sample(n=1).iloc[0].Image\n",
    "\n",
    "    \n",
    "    \n",
    "    train_items = []\n",
    "    for whale in uniq_whales: # loop through unique IDs\n",
    "        this_whale_df = trn_df[trn_df.Id == whale]\n",
    "        other_whale_df = trn_df[trn_df.Id != whale]\n",
    "\n",
    "        this_whale = sample_this_whale()\n",
    "\n",
    "        # sampling same whale if possible\n",
    "        if this_whale_df.shape[0] == 1: \n",
    "            # only a single picture of this whale in dataset -> sample other whale\n",
    "            other_whale = sample_other_whale()\n",
    "            train_items.append([this_whale, other_whale])\n",
    "        else:\n",
    "            # get the img of whale with same id, but not itself\n",
    "            same_whale = this_whale_df[this_whale_df.Image != this_whale].sample(n=1).iloc[0].Image\n",
    "            train_items.append([this_whale, same_whale])\n",
    "\n",
    "        # sampling different whales\n",
    "        this_whale = sample_this_whale()\n",
    "        train_items.append([this_whale, sample_other_whale()])\n",
    "    \n",
    "    if train_on_both_train_and_val:\n",
    "        valid_items = list(zip(val_df.Image.values[:batch_size].tolist(), val_df.Image.values[BS:2*batch_size].tolist()))\n",
    "    else:\n",
    "        valid_items = list(zip(val_df.Image.values[:1465].tolist(), val_df.Image.values[1465:2930].tolist())) #???\n",
    "\n",
    "    train_ds = Dataset(train_items, reader_aug, labeler)\n",
    "    valid_ds = Dataset(valid_items, reader, labeler)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    data = DataBunch(train_dl, valid_dl)\n",
    "    data.train_ds.loss_func = lambda: None\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_data(SZ, dists, BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(data.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x),len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy_mod  map5_mod  cross_entropy_loss  contr_loss  time    \n",
      "0         162.743042  173.225174  0.021502      0.037344  17.087849           58.668659   02:10     \n",
      "1         121.573799  141.476654  0.083618      0.112452  14.079737           16.981930   02:10     \n",
      "2         61.496269   113.136841  0.202048      0.255848  11.201220           28.115734   02:10     \n",
      "3         29.561525   92.655258   0.361775      0.420563  9.182215            20.828007   02:10     \n",
      "4         16.557791   82.454742   0.423549      0.483174  8.152318            23.288803   02:10     \n",
      "5         13.008657   79.646957   0.447099      0.502389  7.865516            24.795168   02:10     \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn = Learner(data, CustomModel(), loss_func=loss_fn, metrics=[accuracy_mod, map5_mod, cross_entropy_loss, contr_loss])\n",
    "learn = learn.clip_grad()\n",
    "learn.split((learn.model.cnn[6], learn.model.head))\n",
    "learn.freeze()\n",
    "\n",
    "learn.fit_one_cycle(6, 1e-2)\n",
    "learn.save(name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get submission:\n",
    "\n",
    "https://github.com/radekosmulski/whale/blob/master/classification_and_metric_learning.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
