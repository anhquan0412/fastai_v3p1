{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.nb_02 import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-4.3871e-06), tensor(1.), tensor(2.3301), tensor(-0.5479))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0205), tensor(0.9801), tensor(2.3301), tensor(-0.5479))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data_normalized()\n",
    "x_train.mean(),x_train.std(),x_train.max(),x_train.min()\n",
    "x_valid.mean(),x_valid.std(),x_valid.max(),x_valid.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.modules.conv._ConvNd.reset_parameters??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784, tensor(10), 50)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,m = x_train.shape\n",
    "c = y_train.max()+1\n",
    "nh = 50\n",
    "n,m,c,nh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model using nn.module + log softmax + cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m,nh,c.tolist())\n",
    "pred = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same with F.nll_loss\n",
    "def nll(input, target): \n",
    "    # input is already softmaxed->logged\n",
    "    return -input[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate to calculate log soft max (numerical stability)\n",
    "def logsumexp(x):\n",
    "    m = x.max(-1)[0] #pytorch max return tuple: max value + argmax\n",
    "    return m + (x-m[:,None]).exp().sum(-1).log()\n",
    "\n",
    "test_near(logsumexp(pred), pred.logsumexp(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.logsumexp(-1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F.nll_loss(F.log_softmax(pred,targ)) == F.cross_entropy(pred,targ)\n",
    "test_near(nll(log_softmax(pred),y_train),F.cross_entropy(pred,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no output for below print command since our modules' submodules are not registered as parameters of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10)]\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x\n",
    "\n",
    "# barebone python\n",
    "# class DummyModule():\n",
    "#     def __init__(self, n_in, nh, n_out):\n",
    "#         self._modules = {}\n",
    "#         self.l1 = nn.Linear(n_in,nh)\n",
    "#         self.l2 = nn.Linear(nh,n_out)\n",
    "        \n",
    "#     def __setattr__(self,k,v): # manually register modules by adding them to a list\n",
    "#         if not k.startswith(\"_\"): self._modules[k] = v\n",
    "#         super().__setattr__(k,v)\n",
    "        \n",
    "#     def __repr__(self): return f'{self._modules}'\n",
    "    \n",
    "#     def parameters(self):\n",
    "#         for l in self._modules.values():\n",
    "#             for p in l.parameters(): yield p\n",
    "                \n",
    "                \n",
    "# Pytorch equivalent: nn.ModuleList \n",
    "# class SequentialModel(nn.Module):\n",
    "#     def __init__(self, layers):\n",
    "#         super().__init__()\n",
    "#         self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "#     def __call__(self, x):\n",
    "#         for l in self.layers: x = l(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([50, 784]),\n",
       " torch.Size([50]),\n",
       " torch.Size([10, 50]),\n",
       " torch.Size([10])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o.shape for o in model.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Sequential as a shortcut to nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#barebone python\n",
    "# def fit():\n",
    "#     for epoch in range(epochs):\n",
    "#         for i in range((n-1)//bs + 1):\n",
    "#             start_i = i*bs\n",
    "#             end_i = start_i+bs\n",
    "#             xb = x_train[start_i:end_i]\n",
    "#             yb = y_train[start_i:end_i]\n",
    "#             loss = loss_func(model(xb), yb)\n",
    "\n",
    "#             loss.backward()\n",
    "#             with torch.no_grad():\n",
    "#                 for p in model.parameters(): p -= p.grad * lr\n",
    "#                 model.zero_grad()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5   # learning rate\n",
    "epochs = 1 # how many epochs to train for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5):\n",
    "        self.params,self.lr = list(params),lr\n",
    "        \n",
    "    def step(self): # at this step, loss grad for each params (weights) has been calculated\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad * lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): \n",
    "        # i can be an array. It will return [img1,img2,...],[label1,label2,...]\n",
    "        return self.x[i],self.y[i] \n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, bs): self.ds,self.bs = ds,bs\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt =  get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb,yb in train_dl:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
    "loss_func = F.cross_entropy\n",
    "def accuracy(out, yb): \n",
    "    # note: 'out' is not softmaxed, but it doesn't matter because max value is still the same, regardless of softmax\n",
    "    return (torch.argmax(out, dim=1)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds,64)\n",
    "valid_dl = DataLoader(valid_ds,64)\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = next(iter(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6360, grad_fn=<NllLossBackward>), tensor(0.8750))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random sampling for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, bs, shuffle=False):\n",
    "        self.n,self.bs,self.shuffle = len(ds),bs,shuffle\n",
    "        \n",
    "    def __iter__(self):\n",
    "        # only return the indices\n",
    "        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
    "        for i in range(0, self.n, self.bs): yield self.idxs[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Sampler(train_ds,6,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(s)\n",
    "b1=next(it)\n",
    "b2=next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20779, 26005,  3458, 12826, 38696, 38937])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([58251,  6891, 33253, 45789, 46624, 30110])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1\n",
    "b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 784]), torch.Size([6]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_temp,y_temp=train_ds[b1]\n",
    "x_temp.shape,y_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f93672ccef0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_temp[0].view(28,28))\n",
    "y_temp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collate function and the new data loader with random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 784]), torch.Size([6]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9364118eb8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEUFJREFUeJzt3XuQ1fV5x/HPs8sCsrAKIojITQQUiUGzgbQYY+KY4mWCpGol1lAnI04bM9raJJYk1Tb1EsdbkjEmqFR0vESjRtMySQw11UwoFykJGmg0SpRLuBq5rMBenv6xh8yK+3vOcu74fb9mnD17nvM9vycnfPa3Z7/n9/2auwtAeuqq3QCA6iD8QKIIP5Aowg8kivADiSL8QKIIP5Aowg8kivADiepVyYP1tj7eV42VPCSQlD3arX2+13ry2KLCb2bTJX1TUr2ke9395ujxfdWoqXZmMYcEEFjii3r82IJ/7Tezekl3STpb0kRJs8xsYqHPB6CyinnPP0XSq+7+mrvvk/SopBmlaQtAuRUT/uGS3uzy/brcfe9iZnPMbLmZLW/V3iIOB6CUigl/d39UeM/1we4+z92b3b25QX2KOByAUiom/Oskjejy/bGSNhTXDoBKKSb8yySNM7MxZtZb0sWSnilNWwDKreCpPndvM7MrJf1EnVN989395ZJ1BqCsiprnd/eFkhaWqBcAFcTHe4FEEX4gUYQfSBThBxJF+IFEEX4gUYQfSBThBxJF+IFEEX4gUYQfSBThBxJF+IFEVXTp7lpWP3RIWG/fsi272NFe4m6A8uPMDySK8AOJIvxAogg/kCjCDySK8AOJIvxAopKZ52/59NSw/sidt4X1e97KHv/cP08Lxx729NKwDlQDZ34gUYQfSBThBxJF+IFEEX4gUYQfSBThBxJV1Dy/ma2VtFNSu6Q2d28uRVPl0LTkzbA+/a4vhfWlX7gzs/bi348Mx7Y+HZaBqijFh3w+7u5bS/A8ACqIX/uBRBUbfpf0UzN70czmlKIhAJVR7K/909x9g5kNkfSsma1x9+e7PiD3Q2GOJPVVvyIPB6BUijrzu/uG3NfNkp6SNKWbx8xz92Z3b25Qn2IOB6CECg6/mTWa2YD9tyV9UtJLpWoMQHkV82v/UElPmdn+53nY3X9ckq4AlF3B4Xf31yR9sIS9lFXb+g1hfdRDFtY3/d2+zNrtY34Qjr3q5M+Fdb2+Piy/fe5JYX3gz1/PrLX9YVN8bCSLqT4gUYQfSBThBxJF+IFEEX4gUYQfSFQyS3fns/sDx4T1MQ39C37usfdlT8VJ0oi+28P6Pwz6eVi/ZuNHMmsrv/6eD12+C8uKp4szP5Aowg8kivADiSL8QKIIP5Aowg8kivADiaroPP++4Y16/Qt/lllvPn1NOH7p4gmZtfp34kty9w1pC+vjj98Y1otx/dH/FdYPr+sb1husPqx/65hlmbWTPjs+HHssy4onizM/kCjCDySK8AOJIvxAogg/kCjCDySK8AOJqug8f5+trTp+fvZS0hddkD1fLUkPf+a5UrfUY+3ekVlbuS/+DMHKPWPDemPd3rC+uyPe6ejetdMya8fc2TscW271RxyeWfP27NdUkjp27gzr1hD/b2s7bVJmbeuk+LMVvd7xsD5wzTthvX7Z6rDue+P/zyuBMz+QKMIPJIrwA4ki/ECiCD+QKMIPJIrwA4ky93g+08zmSzpP0mZ3n5S7b5Ck70saLWmtpIvc/a18B2uyQT7Vzsysd3zslHB8479mb7N9+fD/Dsee229P3Fwej+4cmFn790vPC8f2enNLWG/bFNfr+zeGddVlr2XQvmNXONTq47UC2v883h781b9qCOvXfeKHmbVT+74Rjn2hZVxY39o6IKzPHbwqs5ZvjYR8Wjqyt2yXpClLLwvrjU81ZdaOfPrlcGz7jh2ZtSW+SDt8e7y4RU5Pzvz3S5p+wH3XSlrk7uMkLcp9D+AQkjf87v68pAO3lJkhaUHu9gJJ55e4LwBlVuh7/qHuvlGScl+HlK4lAJVQ9s/2m9kcSXMkqa/6lftwAHqo0DP/JjMbJkm5r5uzHuju89y92d2bGxRfoAKgcgoN/zOSZuduz5bEGrDAISZv+M3sEUmLJU0ws3Vm9jlJN0s6y8xekXRW7nsAh5C88/yllG+ePy/Lnr6sH3dcOPT+RQ+E9SH18Vz6+Pv/NrM25iv/E45VBV/jA9X1ja9bbznr5LC+4aPxfHif47PnnCXphKOy129Y8at4nYPe2+Nz04C1YVntwbvM3cPjsfsGt4f1mz7+eFi/eED8sZdofYibtk0Mxy4+/4TM2i/XPai39/yhZPP8AN6HCD+QKMIPJIrwA4ki/ECiCD+QqIou3V20YMqsY0A8pdXf4ktP8+m7LXv2xHrFz2318c/Yjj3FXW5czHP3/dHSsH7cj4o7frT49jhtLe7Ji3BUkeMXNMbTcf90W3wp9Ipz78ysfXVwvFX9mK+cllnb8y89jzRnfiBRhB9IFOEHEkX4gUQRfiBRhB9IFOEHEnVozfMHl/TuuiHeMrlfXXFbVZ928YrsY18Qf8bgd28PDusdC+IlEA9/fHlY97Z4i3CUXsfu3WH9xC/Fc/XnjLo0s7b4g0+EY08auz6z9se+reHYrjjzA4ki/ECiCD+QKMIPJIrwA4ki/ECiCD+QqENqnr9l5pTM2o3jv1fWY39neJ7luQOvt8bbZB9762FhfeIpV4b1474c9FbFZcNT1tHSEtY3bTm84Of+0MDsrc1X1u/t8fNw5gcSRfiBRBF+IFGEH0gU4QcSRfiBRBF+IFF55/nNbL6k8yRtdvdJufuul3S5pC25h81194XFNlM3YEBYv/zG7OucT48vqdeujnj9+v518RM8saspszb3sUvCsWMf3BLWT3z4tbD+3b+cF9Zv/9b0zFrbuuxrv1E46xVH57d3fCisP/7Rb2fW2j1+7gcWT8usbdsVr/3QVU/O/PdL6u5f1x3uPjn3X9HBB1BZecPv7s9L2l6BXgBUUDHv+a80s1+b2XwzG1iyjgBURKHhv1vSWEmTJW2UdFvWA81sjpktN7Plrer5544BlFdB4Xf3Te7e7u4dku6RlHnFjbvPc/dmd29uUJ9C+wRQYgWF38yGdfl2pqSXStMOgErpyVTfI5LOkDTYzNZJuk7SGWY2WZJLWivpijL2CKAM8obf3Wd1c/d9BR8xWHt/zR0TwqGfbXqh4MO2eHtYP2fVzLB+2Nf6Z9ZGL10cjo2PLD25JHudAkm6ZUY8d3vVJaMya8O/wTx/IeqPiK+3f+XaiXH903eF9fXt+zJrJ917dTh2wo0vZtbe2hvvX9EVn/ADEkX4gUQRfiBRhB9IFOEHEkX4gURVdOnujiMa1fKJ7Gmtn5x1ezi+paMhs7bL462JP3bfF8P6qH9bGtbLuQ12/RHZ0z6SVG/xz+jW/izPfbDyXZK749Ejw/qHB8RbcB//n/FHX0Y9lV0b/WwR/xYPYql2zvxAogg/kCjCDySK8AOJIvxAogg/kCjCDySqovP8bf2kLZPrM+vjGxrD8Xf9cURm7fF/zF6+WpJGLvxlWC9qpjy4TFmS6k8cF9a/N/XBsN7uHWG9KV75O1l1k7Mvu33nlngL7e07+oX1pr9+O6yP37osrEcq9akNzvxAogg/kCjCDySK8AOJIvxAogg/kCjCDySqovP8fba2auz92UtJjzn68nD8hO9mz832+d94XrWuMf4Mwa6/mBTW138q+xrqgUfuDMc+dvL8sD66Vzyn/ON34vqQ57Jf0/KtQlB+eZfP/s6YsH72+Jcza88/8OFw7Mi74+XS21vjNRgOBZz5gUQRfiBRhB9IFOEHEkX4gUQRfiBRhB9IVN55fjMbIekBSUdL6pA0z92/aWaDJH1f0mhJayVd5O5vRc/l+/ap7fXfZ9bHX5Fdk+LrnOubmsKxa+ePDOuXnfCzsD6r6VeZtWN7ZW/f3SlfPXbNigvD+qg3flPU85dVXfb6DbsuiOfad30mvmbe1hwW1n/3xaMya0PXl3F9h0NET878bZKucfcTJX1E0ufNbKKkayUtcvdxkhblvgdwiMgbfnff6O4rcrd3SlotabikGZIW5B62QNL55WoSQOkd1Ht+Mxst6RRJSyQNdfeNUucPCElDSt0cgPLpcfjNrL+kJyRd7e47DmLcHDNbbmbLW7W3kB4BlEGPwm9mDeoM/kPu/mTu7k1mNixXHyZpc3dj3X2euze7e3OD+pSiZwAlkDf8ZmaS7pO02t27bqP7jKTZuduzJT1d+vYAlIt5ni19zew0SS9IWqXOqT5JmqvO9/2PSRop6Q1JF7r79ui5mmyQT7Uzi+25LPJt2Vw3YWxmbdupg8Kxm6e1h/VeTfHloeO+vjust69+JayXU/2448L6mquzp9vumX5vOParX4sv8W56NM/y2B3x6/5+tMQXaYdvj9eSz8k7z+/uv5CU9WS1mWQAefEJPyBRhB9IFOEHEkX4gUQRfiBRhB9IVN55/lKq5Xl+dK9l5tSwfskN/xHWf7btxMza1pvipbf7LCx8m+tUHcw8P2d+IFGEH0gU4QcSRfiBRBF+IFGEH0gU4QcSVdEtulEFUz4Qll+9ON66/JGZ3w7rl827KqyPuDV7q+vGozeGY9sbeod1fx9sk11NnPmBRBF+IFGEH0gU4QcSRfiBRBF+IFGEH0gU1/MD7yNczw8gL8IPJIrwA4ki/ECiCD+QKMIPJIrwA4nKG34zG2Fmz5nZajN72cyuyt1/vZmtN7OVuf/OKX+7AEqlJ4t5tEm6xt1XmNkASS+a2bO52h3ufmv52gNQLnnD7+4bJW3M3d5pZqslDS93YwDK66De85vZaEmnSFqSu+tKM/u1mc03s4EZY+aY2XIzW96qvUU1C6B0ehx+M+sv6QlJV7v7Dkl3SxorabI6fzO4rbtx7j7P3ZvdvblBfUrQMoBS6FH4zaxBncF/yN2flCR33+Tu7e7eIekeSVPK1yaAUuvJX/tN0n2SVrv77V3uH9blYTMlvVT69gCUS0/+2j9N0qWSVpnZytx9cyXNMrPJklzSWklXlKVDAGXRk7/2/0JSd9cHLyx9OwAqhU/4AYki/ECiCD+QKMIPJIrwA4ki/ECiCD+QKMIPJIrwA4ki/ECiCD+QKMIPJIrwA4ki/ECiKrpFt5ltkfT7LncNlrS1Yg0cnFrtrVb7kuitUKXsbZS7H9WTB1Y0/O85uNlyd2+uWgOBWu2tVvuS6K1Q1eqNX/uBRBF+IFHVDv+8Kh8/Uqu91WpfEr0Vqiq9VfU9P4DqqfaZH0CVVCX8ZjbdzP7PzF41s2ur0UMWM1trZqtyOw8vr3Iv881ss5m91OW+QWb2rJm9kvva7TZpVeqtJnZuDnaWruprV2s7Xlf8134zq5f0W0lnSVonaZmkWe7+m4o2ksHM1kpqdveqzwmb2emSdkl6wN0n5e67RdJ2d78594NzoLt/uUZ6u17Srmrv3JzbUGZY152lJZ0v6W9Uxdcu6OsiVeF1q8aZf4qkV939NXffJ+lRSTOq0EfNc/fnJW0/4O4Zkhbkbi9Q5z+eisvorSa4+0Z3X5G7vVPS/p2lq/raBX1VRTXCP1zSm12+X6fa2vLbJf3UzF40sznVbqYbQ3Pbpu/fPn1Ilfs5UN6dmyvpgJ2la+a1K2TH61KrRvi72/2nlqYcprn7qZLOlvT53K+36Jke7dxcKd3sLF0TCt3xutSqEf51kkZ0+f5YSRuq0Ee33H1D7utmSU+p9nYf3rR/k9Tc181V7udPamnn5u52llYNvHa1tON1NcK/TNI4MxtjZr0lXSzpmSr08R5m1pj7Q4zMrFHSJ1V7uw8/I2l27vZsSU9XsZd3qZWdm7N2llaVX7ta2/G6Kh/yyU1l3CmpXtJ8d7+h4k10w8yOU+fZXurcxPThavZmZo9IOkOdV31tknSdpB9KekzSSElvSLrQ3Sv+h7eM3s5Q56+uf9q5ef977Ar3dpqkFyStktSRu3uuOt9fV+21C/qapSq8bnzCD0gUn/ADEkX4gUQRfiBRhB9IFOEHEkX4gUQRfiBRhB9I1P8DTXvh/ukoIG4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Question: not sure why we need to use collate since train_ds[[i1,i2,i3]] is good enough to get batch containing x and y,\n",
    "# instead of using collate_fn([train_ds[i] for i in [i1,i2,i3]])\n",
    "# # Answer: so if we want to do something different for each sample in a batch (e.g data augmentation), we can define our own collate function\n",
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    # xs is all imgs in that batch (6)\n",
    "    # perform any data manipulation (augmentation, ...) on xs here\n",
    "    return torch.stack(xs),torch.stack(ys)\n",
    "x_temp,y_temp = collate([train_ds[i] for i in b1])\n",
    "x_temp.shape,y_temp.shape # (torch.Size([6, 784]), torch.Size([6]))\n",
    "plt.imshow(x_temp[0].view(28,28))\n",
    "y_temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataLoader():\n",
    "#     def __init__(self, ds, sampler, collate_fn=collate):\n",
    "#         self.ds,self.sampler,self.collate_fn = ds,sampler,collate_fn\n",
    "        \n",
    "#     def __iter__(self):\n",
    "#         for s in self.sampler: yield self.ds[s]\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, sampler, collate_fn=collate):\n",
    "        self.ds,self.sampler,self.collate_fn = ds,sampler,collate_fn\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for s in self.sampler: yield self.collate_fn([self.ds[i] for i in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = Sampler(train_ds, bs, shuffle=True)\n",
    "valid_samp = Sampler(valid_ds, bs, shuffle=False)\n",
    "\n",
    "train_dl = DataLoader(train_ds, sampler=train_samp, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f93640f1a90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = next(iter(valid_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6373, grad_fn=<NllLossBackward>), tensor(0.7656))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "\n",
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2708, grad_fn=<NllLossBackward>), tensor(0.9219))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check train loss\n",
    "xb_tr,yb_tr = next(iter(train_dl))\n",
    "loss,acc = loss_func(model(xb_tr), yb_tr), accuracy(model(xb_tr), yb_tr)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "\n",
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate) # shuffle true\n",
    "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)# shuffle false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = next(iter(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8562, grad_fn=<NllLossBackward>), tensor(0.7656))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal dataloader\n",
    "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True)\n",
    "valid_dl = DataLoader(valid_ds, bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        # Handle batchnorm / dropout\n",
    "        model.train()\n",
    "#         print(model.training)\n",
    "        for xb,yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "#         print(model.training)\n",
    "\n",
    "        # record loss at each epoch: cummulate val loss for the entire epoch and average out \n",
    "        with torch.no_grad():\n",
    "            tot_loss,tot_acc = 0.,0.\n",
    "            for xb,yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                tot_loss += loss_func(pred, yb)\n",
    "                tot_acc  += accuracy (pred,yb)\n",
    "        nv = len(valid_dl)\n",
    "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
    "    return tot_loss/nv, tot_acc/nv\n",
    "\n",
    "def get_dataloaders(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.functional.cross_entropy(input, target, weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.6121) tensor(0.8119)\n",
      "1 tensor(0.5967) tensor(0.8220)\n",
      "2 tensor(0.5394) tensor(0.8461)\n",
      "3 tensor(0.5082) tensor(0.8583)\n",
      "4 tensor(0.5283) tensor(0.8601)\n"
     ]
    }
   ],
   "source": [
    "train_dl,valid_dl = get_dataloaders(train_ds, valid_ds, bs)\n",
    "model,opt = get_model()\n",
    "loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
