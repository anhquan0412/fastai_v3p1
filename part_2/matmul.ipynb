{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "# from fastai import datasets\n",
    "import pickle, gzip, math, torch, matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "\n",
    "input_path = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'eq'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operator.add(1,2)\n",
    "operator.eq(2,2)\n",
    "operator.eq(2,1)\n",
    "operator.eq.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fnc(a,b,comp,comp_name=None):\n",
    "    if not comp_name: comp_name=comp.__name__\n",
    "    assert comp(a,b),f'{comp_name}\\n{a}\\n{b}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fnc(1+1,2,operator.eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab KMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "# from fastai import datasets\n",
    "import pickle, gzip, math, torch, matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    # Path to training images and corresponding labels provided as numpy arrays\n",
    "    kmnist_train_images_path = input_path/\"kmnist-train-imgs.npz\"\n",
    "    kmnist_train_labels_path = input_path/\"kmnist-train-labels.npz\"\n",
    "\n",
    "    # Path to the test images and corresponding labels\n",
    "    kmnist_test_images_path = input_path/\"kmnist-test-imgs.npz\"\n",
    "    kmnist_test_labels_path = input_path/\"kmnist-test-labels.npz\"\n",
    "    import numpy\n",
    "    train = numpy.load(kmnist_train_images_path)['arr_0']\n",
    "    train_labels = numpy.load(kmnist_train_labels_path)['arr_0']\n",
    "\n",
    "    # Load the test data from the corresponding npz files\n",
    "    test = numpy.load(kmnist_test_images_path)['arr_0']\n",
    "    test_labels = numpy.load(kmnist_test_labels_path)['arr_0']\n",
    "    x_train,y_train,x_valid,y_valid = map(tensor, (train,train_labels,test,test_labels))\n",
    "    x_train = x_train.view(x_train.shape[0],-1).to(dtype=torch.float32)/255\n",
    "    x_valid = x_valid.view(x_valid.shape[0],-1).to(dtype=torch.float32)/255\n",
    "    \n",
    "    return x_train,y_train,x_valid,y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to training images and corresponding labels provided as numpy arrays\n",
    "kmnist_train_images_path = input_path/\"kmnist-train-imgs.npz\"\n",
    "kmnist_train_labels_path = input_path/\"kmnist-train-labels.npz\"\n",
    "\n",
    "# Path to the test images and corresponding labels\n",
    "kmnist_test_images_path = input_path/\"kmnist-test-imgs.npz\"\n",
    "kmnist_test_labels_path = input_path/\"kmnist-test-labels.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "train = numpy.load(kmnist_train_images_path)['arr_0']\n",
    "train_labels = numpy.load(kmnist_train_labels_path)['arr_0']\n",
    "\n",
    "# Load the test data from the corresponding npz files\n",
    "test = numpy.load(kmnist_test_images_path)['arr_0']\n",
    "test_labels = numpy.load(kmnist_test_labels_path)['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0, dtype=torch.uint8), tensor(9, dtype=torch.uint8))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train,x_valid,y_valid = map(tensor, (train,train_labels,test,test_labels))\n",
    "n,c,_ = x_train.shape\n",
    "y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd8e15c7f28>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([10000, 784]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.view(x_train.shape[0],-1)\n",
    "x_valid = x_valid.view(x_valid.shape[0],-1)\n",
    "x_train.shape,x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_valid = x_train.to(dtype=torch.float64),x_valid.to(dtype=torch.float64) # for matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0153)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9679)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp=torch.randn(1000)\n",
    "temp.mean()\n",
    "temp.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_near(a,b):\n",
    "    test_fnc(a,b,lambda x,y: torch.allclose(x,y,rtol=1e-3,atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump pythob mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac = a.shape # n_rows * n_cols\n",
    "    br,bc = b.shape\n",
    "    assert ac==br\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc):\n",
    "            for k in range(ac): # or br\n",
    "                c[i,j] += a[i,k] * b[k,j]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn(784,10)\n",
    "bias = torch.zeros(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = x_valid[:5]\n",
    "m2 = weights\n",
    "m1.shape,m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(matmul(m1,m2),\n",
    "          torch.mm(m1.to(dtype=torch.float32),m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585 ms ± 7.39 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_bc(m1,m2):\n",
    "    m1 = m1.to(dtype=torch.float32)\n",
    "    result = torch.zeros(m1.shape[0],m2.shape[1])\n",
    "    for i in range(m1.shape[0]):\n",
    "        m1_row = m1[i,:]\n",
    "        result[i,:] = (m1_row[:,None] * m2).sum(dim=0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221 µs ± 99.2 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matmul_bc(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(matmul_bc(m1,m2),\n",
    "          torch.mm(m1.to(dtype=torch.float32),m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1904), tensor(0.3475))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(),x_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: plot normal distribution with mean 0 and different std to get a feel of what it looks like"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
