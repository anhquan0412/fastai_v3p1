{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.nb_09 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get imagenette data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = datasets.untar_data(datasets.URLs.IMAGENETTE_160)\n",
    "\n",
    "tfms = [make_rgb, ResizeFixed(128), to_byte_tensor, to_float_tensor]\n",
    "bs=128\n",
    "\n",
    "il = ImageList.from_files(path, tfms=tfms)\n",
    "sd = SplitData.split_by_func(il, partial(grandparent_splitter, valid_name='val'))\n",
    "ll = label_by_func(sd, parent_labeler, proc_y=CategoryProcessor())\n",
    "data = ll.to_databunch(bs, c_in=3, c_out=10, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs = [32]*4\n",
    "\n",
    "cbfs = [partial(AvgStatsCallback,accuracy), CudaCallback,\n",
    "        partial(BatchTransformXCallback, norm_imagenette)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining learner and runner into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_getter(m): return m.parameters()\n",
    "\n",
    "class Learner():\n",
    "    def __init__(self, model, data, loss_func, opt_func=sgd_opt, lr=1e-2, # from old learner\n",
    "                 splitter=param_getter, # func to create different param groups for differential learning\n",
    "                 cbs=None, cb_funcs=None): # from old Runner\n",
    "        self.model,self.data,self.loss_func,self.opt_func,self.lr,self.splitter = model,data,loss_func,opt_func,lr,splitter\n",
    "        self.in_train,self.logger,self.opt = False,print,None\n",
    "        \n",
    "\n",
    "        self.cbs = []\n",
    "        self.add_cb(TrainEvalCallback())\n",
    "        self.add_cbs(cbs)\n",
    "        self.add_cbs(cbf() for cbf in listify(cb_funcs))\n",
    "\n",
    "    def add_cbs(self, cbs):\n",
    "        for cb in listify(cbs): self.add_cb(cb)\n",
    "            \n",
    "    def add_cb(self, cb):\n",
    "        cb.set_runner(self)         # save this learner into cb as an attribute\n",
    "        setattr(self, cb.name, cb) # save callback object under its snake_name to runner\n",
    "        # e.g. <learner obj>.train_eval = TrainEvalCallback(<init_input from partial)()\n",
    "        self.cbs.append(cb)\n",
    "\n",
    "    def remove_cbs(self, cbs):\n",
    "        for cb in listify(cbs): self.cbs.remove(cb)\n",
    "            \n",
    "    def one_batch(self, i, xb, yb): # add i parameter to save self.iter (will be used later???)\n",
    "        try:\n",
    "            self.iter = i\n",
    "            self.xb,self.yb = xb,yb;                        self('begin_batch')\n",
    "            self.pred = self.model(self.xb);                self('after_pred')\n",
    "            self.loss = self.loss_func(self.pred, self.yb); self('after_loss')\n",
    "            if not self.in_train: return\n",
    "            self.loss.backward();                           self('after_backward')\n",
    "            self.opt.step();                                self('after_step')\n",
    "            self.opt.zero_grad()\n",
    "        except CancelBatchException:                        self('after_cancel_batch')\n",
    "        finally:                                            self('after_batch')\n",
    "\n",
    "    def all_batches(self):\n",
    "        self.iters = len(self.dl)\n",
    "        try:\n",
    "            for i,(xb,yb) in enumerate(self.dl): self.one_batch(i, xb, yb)\n",
    "        except CancelEpochException: self('after_cancel_epoch')\n",
    "\n",
    "    def do_begin_fit(self, epochs):\n",
    "        self.epochs,self.loss = epochs,tensor(0.)\n",
    "        self('begin_fit')\n",
    "\n",
    "    def do_begin_epoch(self, epoch):\n",
    "        self.epoch,self.dl = epoch,self.data.train_dl\n",
    "        return self('begin_epoch')\n",
    "\n",
    "    def fit(self, epochs, cbs=None, reset_opt=False):\n",
    "        # You can pass callbacks to fit() (temporary callback) and they will be removed when done\n",
    "        self.add_cbs(cbs)\n",
    "        # create optimizer on fit(). You can choose to reset opt\n",
    "        if reset_opt or not self.opt: self.opt = self.opt_func(self.splitter(self.model), lr=self.lr)\n",
    "            \n",
    "        try:\n",
    "            self.do_begin_fit(epochs)\n",
    "            for epoch in range(epochs):\n",
    "                self.do_begin_epoch(epoch)\n",
    "                if not self('begin_epoch'): self.all_batches()\n",
    "\n",
    "                with torch.no_grad(): \n",
    "                    self.dl = self.data.valid_dl\n",
    "                    if not self('begin_validate'): self.all_batches()\n",
    "                self('after_epoch')\n",
    "            \n",
    "        except CancelTrainException: self('after_cancel_train')\n",
    "        finally:\n",
    "            self('after_fit')\n",
    "            self.remove_cbs(cbs)\n",
    "\n",
    "    ALL_CBS = {'begin_batch', 'after_pred', 'after_loss', 'after_backward', 'after_step',\n",
    "        'after_cancel_batch', 'after_batch', 'after_cancel_epoch', 'begin_fit',\n",
    "        'begin_epoch', 'begin_epoch', 'begin_validate', 'after_epoch',\n",
    "        'after_cancel_train', 'after_fit'}\n",
    "    \n",
    "    def __call__(self, cb_name):\n",
    "        res = False\n",
    "        assert cb_name in self.ALL_CBS # make sure only defined cb func is used\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order): res = cb(cb_name) and res\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgStatsCallback(Callback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "        \n",
    "    def after_loss(self):\n",
    "        stats = self.train_stats if self.in_train else self.valid_stats\n",
    "        with torch.no_grad(): stats.accumulate(self.run)\n",
    "    \n",
    "    def after_epoch(self):\n",
    "#         print(self.train_stats)\n",
    "#         print(self.valid_stats)\n",
    "        #We use the logger function of the `Learner` here, \n",
    "    # it can be customized to write in a file or in a progress bar\n",
    "        self.logger(self.train_stats)\n",
    "        self.logger(self.valid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfs = [partial(AvgStatsCallback,accuracy),\n",
    "        CudaCallback,\n",
    "        partial(BatchTransformXCallback, norm_imagenette)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner(nfs, data, lr, layer, loss_func=F.cross_entropy,\n",
    "                cb_funcs=None, opt_func=sgd_opt, **kwargs):\n",
    "    model = get_cnn_model(data, nfs, layer, **kwargs)\n",
    "    init_cnn(model)\n",
    "    return Learner(model, data, loss_func, lr=lr, cb_funcs=cb_funcs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [1.8940630392527533, tensor(0.3362, device='cuda:0')]\n",
      "valid: [1.86956640625, tensor(0.3820, device='cuda:0')]\n",
      "CPU times: user 2.86 s, sys: 1.41 s, total: 4.27 s\n",
      "Wall time: 4.92 s\n"
     ]
    }
   ],
   "source": [
    "learn = get_learner(nfs, data, 0.4, conv_layer, cb_funcs=cbfs)\n",
    "%time learn.fit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
